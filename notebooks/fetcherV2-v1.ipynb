{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RateLimiter:\n",
    "    def __init__(self, rate: int, burst: int):\n",
    "        \"\"\"Token bucket rate limiter\"\"\"\n",
    "        self.rate = rate\n",
    "        self.burst = burst\n",
    "        self.tokens = burst\n",
    "        self.last_refill_time = asyncio.get_event_loop().time()\n",
    "\n",
    "    async def acquire(self):\n",
    "        \"\"\"Acquire a token, blocking if necessary\"\"\"\n",
    "        while self.tokens < 1:\n",
    "            await self._refill()\n",
    "            await asyncio.sleep(0.1) # sleep to avoid busy waiting\n",
    "        self.tokens -= 1\n",
    "\n",
    "    async def _refill(self):\n",
    "        \"\"\"Refills bucket based on rate\"\"\"\n",
    "        current_time = asyncio.get_event_loop().time() # get current time\n",
    "        elapsed_time = current_time - self.last_refill_time # calculate elapsed time\n",
    "        new_tokens = elapsed_time * self.rate # calculate new tokens\n",
    "        self.tokens = min(self.tokens + new_tokens, self.burst) # add new tokens to bucket\n",
    "        self.last_refill_time = current_time # update last refil time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HttpRequestFetcher:\n",
    "    def __init__(self, rate_limiter: RateLimiter, retries: int = 2):\n",
    "        \"\"\"Fetcher with specified rate limiter and number of retries\"\"\"\n",
    "        self.rate_limiter = rate_limiter\n",
    "        self.retries = retries\n",
    "        self.session = None\n",
    "    \n",
    "    # context manager\n",
    "    async def aenter(self): self.session = aiohttp.ClientSession()\n",
    "    async def aexit(self, exc_type, exc, tb): await self.close()\n",
    "\n",
    "    async def fetch(self, url: str):\n",
    "        for attempt in range(self.retries + 1): # try up to self.retries + 1 times\n",
    "            await self.rate_limiter.acquire() # acquire token\n",
    "            try:\n",
    "                async with self.session.get(url) as response: # get response\n",
    "                    response.raise_for_status() # raise exception if status is not 200\n",
    "                    return await response.text() # return response text\n",
    "            except aiohttp.ClientError as e: # if exception is raised\n",
    "                if attempt == self.retries: # if last attempt\n",
    "                    print(f\"Failed to fetch {url}: {e}\") # print error\n",
    "                    return None\n",
    "                backoff_duration = 2 ** attempt # exponential backoff\n",
    "                await asyncio.sleep(backoff_duration) # sleep for backoff duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchRequestExecutor:\n",
    "    def __init__(self, concurrency_limit: int = 10):\n",
    "        \"\"\"Batch request executor with specified fetcher and batch size\"\"\"\n",
    "        self.concurrency_limit = concurrency_limit\n",
    "\n",
    "    async def execute(self, fetcher: HttpRequestFetcher, urls: List[str]) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"Executes batch requests and returns successful and failed urls\"\"\"\n",
    "        async with fetcher:\n",
    "            sem = asyncio.Semaphore(self.concurrency_limit) # create semaphore to control batch size (or concurrency)\n",
    "            tasks = [self._fetch(sem, url) for url in urls] # create tasks\n",
    "            results = await asyncio.gather(*tasks, return_exceptions=True) # gather results\n",
    "            successful_urls = [result for result in results if not isinstance(result, Exception)] # filter out exceptions\n",
    "            failed_urls = [urls[i] for i, result in enumerate(results) if isinstance(result, Exception)] # collect failed urls\n",
    "            return successful_urls, failed_urls\n",
    "    \n",
    "    async def _fetch(self, sem: asyncio.Semaphore, url: str, fetcher: HttpRequestFetcher):\n",
    "        \"\"\"Fetches url\"\"\"\n",
    "        async with sem:\n",
    "            response_parsed = await fetcher.fetch(url)\n",
    "            if response_parsed is not None:\n",
    "                return response_parsed\n",
    "            else:\n",
    "                raise Exception(\"Failed to fetch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
